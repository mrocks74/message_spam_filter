{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from math import log, sqrt\n",
    "import re\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  labels                                            message\n",
       "0    ham  Go until jurong point, crazy.. Available only ...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    ham  U dun say so early hor... U c already then say...\n",
       "4    ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mails = pd.read_csv('spam.csv', encoding = 'latin-1')\n",
    "mails.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis = 1, inplace = True)\n",
    "mails.rename(columns = {'v1': 'labels', 'v2': 'message'}, inplace = True)\n",
    "mails.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mails['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  label\n",
       "0  Go until jurong point, crazy.. Available only ...      0\n",
       "1                      Ok lar... Joking wif u oni...      0\n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...      1\n",
       "3  U dun say so early hor... U c already then say...      0\n",
       "4  Nah I don't think he goes to usf, he lives aro...      0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mails['label'] = mails['labels'].map({'ham': 0, 'spam': 1})\n",
    "mails.drop(['labels'], axis = 1, inplace = True)\n",
    "mails.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       go until jurong point crazy available only in ...\n",
      "1                                 ok lar joking wif u oni\n",
      "2       free entry in 2 a wkly comp to win fa cup fina...\n",
      "3             u dun say so early hor u c already then say\n",
      "4       nah i don t think he goes to usf he lives arou...\n",
      "5       freemsg hey there darling it s been 3 week s n...\n",
      "6       even my brother is not like to speak with me t...\n",
      "7       as per your request melle melle oru minnaminun...\n",
      "8       winner as a valued network customer you have b...\n",
      "9       had your mobile 11 months or more u r entitled...\n",
      "10      i m gonna be home soon and i don t want to tal...\n",
      "11      six chances to win cash from 100 to 20 000 pou...\n",
      "12      urgent you have won a 1 week free membership i...\n",
      "13      i ve been searching for the right words to tha...\n",
      "14                      i have a date on sunday with will\n",
      "15      xxxmobilemovieclub to use your credit click th...\n",
      "16                                 oh k i m watching here\n",
      "17      eh u remember how 2 spell his name yes i did h...\n",
      "18      fine if thatåõs the way u feel thatåõs the way...\n",
      "19      england v macedonia dont miss the goals team n...\n",
      "20               is that seriously how you spell his name\n",
      "21      i û m going to try for 2 months ha ha only joking\n",
      "22        so ì_ pay first lar then when is da stock comin\n",
      "23      aft i finish my lunch then i go str down lor a...\n",
      "24      ffffffffff alright no way i can meet up with y...\n",
      "25      just forced myself to eat a slice i m really n...\n",
      "26                          lol your always so convincing\n",
      "27      did you catch the bus are you frying an egg di...\n",
      "28      i m back amp we re packing the car now i ll le...\n",
      "29      ahhh work i vaguely remember that what does it...\n",
      "                              ...                        \n",
      "5542             armand says get your ass over to epsilon\n",
      "5543                u still havent got urself a jacket ah\n",
      "5544    i m taking derek amp taylor to walmart if i m ...\n",
      "5545        hi its in durban are you still on this number\n",
      "5546             ic there are a lotta childporn cars then\n",
      "5547    had your contract mobile 11 mnths latest motor...\n",
      "5548                     no i was trying it all weekend v\n",
      "5549    you know wot people wear t shirts jumpers hat ...\n",
      "5550            cool what time you think you can get here\n",
      "5551    wen did you get so spiritual and deep that s g...\n",
      "5552    have a safe trip to nigeria wish you happiness...\n",
      "5553                           hahaha use your brain dear\n",
      "5554    well keep in mind i ve only got enough gas for...\n",
      "5555    yeh indians was nice tho it did kane me off a ...\n",
      "5556    yes i have so that s why u texted pshew missin...\n",
      "5557    no i meant the calculation is the same that lt...\n",
      "5558                                sorry i ll call later\n",
      "5559    if you aren t here in the next lt gt hours imm...\n",
      "5560                      anything lor juz both of us lor\n",
      "5561    get me out of this dump heap my mom decided to...\n",
      "5562    ok lor sony ericsson salesman i ask shuhui the...\n",
      "5563                                   ard 6 like dat lor\n",
      "5564    why don t you wait til at least wednesday to s...\n",
      "5565                                            huh y lei\n",
      "5566    reminder from o2 to get 2 50 pounds free call ...\n",
      "5567    this is the 2nd time we have tried 2 contact u...\n",
      "5568                 will ì_ b going to esplanade fr home\n",
      "5569    pity was in mood for that so any other suggest...\n",
      "5570    the guy did some bitching but i acted like i d...\n",
      "5571                            rofl its true to its name\n",
      "Name: message, Length: 5572, dtype: object\n"
     ]
    }
   ],
   "source": [
    "processed=mails['message']\n",
    "# use regular expressions to replace email addresses, URLs, phone numbers, other numbers\n",
    "\n",
    "# Replace email addresses with 'email'\n",
    "processed = processed.str.replace(r'^.+@[^\\.].*\\.[a-z]{2,}$',\n",
    "                                 'emailaddress')\n",
    "\n",
    "# Replace URLs with 'webaddress'\n",
    "processed = processed.str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$',\n",
    "                                  'webaddress')\n",
    "\n",
    "# Replace money symbols with 'moneysymb' (£ can by typed with ALT key + 156)\n",
    "processed = processed.str.replace(r'£|\\$', 'moneysymb')\n",
    "    \n",
    "# Replace 10 digit phone numbers (formats include paranthesis, spaces, no spaces, dashes) with 'phonenumber'\n",
    "processed = processed.str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$',\n",
    "                                  'phonenumbr')\n",
    "\n",
    "# Remove punctuation\n",
    "processed = processed.str.replace(r'[^\\w\\d\\s]', ' ')\n",
    "\n",
    "# Replace whitespace between terms with a single space\n",
    "processed = processed.str.replace(r'\\s+', ' ')\n",
    "\n",
    "# Remove leading and trailing whitespace\n",
    "processed = processed.str.replace(r'^\\s+|\\s+?$', '')\n",
    "\n",
    "\n",
    "# change words to lower case - Hello, HELLO, hello are all the same word\n",
    "processed = processed.str.lower()\n",
    "print(processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: 7268\n",
      "Most common words: [('u', 1192), ('call', 672), ('2', 514), ('go', 453), ('get', 451), ('ur', 385), ('gt', 318), ('4', 317), ('lt', 316), ('come', 301), ('ok', 292), ('free', 284), ('know', 274), ('day', 273), ('love', 260)]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# remove stop words from text messages\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "processed = processed.apply(lambda x: ' '.join(\n",
    "    term for term in x.split() if term not in stop_words))\n",
    "# Remove word stems using a Porter stemmer\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "processed = processed.apply(lambda x: ' '.join(ps.stem(term) for term in x.split()))\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "# create bag-of-words\n",
    "all_words = []\n",
    "\n",
    "for message in processed:\n",
    "    words = word_tokenize(message)\n",
    "    for w in words:\n",
    "        all_words.append(w)\n",
    "        \n",
    "all_words = nltk.FreqDist(all_words)\n",
    "\n",
    "# print the total number of words and the 15 most common words\n",
    "print('Number of words: {}'.format(len(all_words)))\n",
    "print('Most common words: {}'.format(all_words.most_common(15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4179\n",
      "1393\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "# split the data into training and testing datasets\n",
    "trainData, testData = model_selection.train_test_split(mails['message'], test_size =0.25, random_state=1)\n",
    "\n",
    "print(len(trainData))\n",
    "print(len(testData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_message(message, lower_case = True, stem = True, stop_words = True, gram = 2):\n",
    "    if lower_case:\n",
    "        message = message.lower()\n",
    "    words = word_tokenize(message)\n",
    "    words = [w for w in words if len(w) > 2]\n",
    "\n",
    "    if stop_words:\n",
    "        sw = stopwords.words('english')\n",
    "        words = [word for word in words if word not in sw]\n",
    "    if stem:\n",
    "        stemmer = PorterStemmer()\n",
    "        words = [stemmer.stem(word) for word in words] \n",
    "    words=list(nltk.ngrams(words,gram))\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpamClassifier(object):\n",
    "    def __init__(self, trainData):\n",
    "        self.mails, self.labels = list(trainData['message']),list( trainData['label'])\n",
    "        #print(self.mails)\n",
    "    def train(self):\n",
    "        self.calc_TF_and_IDF()\n",
    "        self.calc_TF_IDF()\n",
    "        \n",
    "    def calc_prob(self):\n",
    "        self.prob_spam = dict()\n",
    "        self.prob_ham = dict()\n",
    "        for word in self.tf_spam:\n",
    "            self.prob_spam[word] = (self.tf_spam[word] + 1) / (self.spam_words + \\\n",
    "                                                                len(list(self.tf_spam.keys())))\n",
    "        for word in self.tf_ham:\n",
    "            self.prob_ham[word] = (self.tf_ham[word] + 1) / (self.ham_words + \\\n",
    "                                                                len(list(self.tf_ham.keys())))\n",
    "        self.prob_spam_mail, self.prob_ham_mail = self.spam_mails / self.total_mails, self.ham_mails / self.total_mails \n",
    "\n",
    "\n",
    "    def calc_TF_and_IDF(self):\n",
    "        noOfMessages = len(self.mails)\n",
    "        self.spam_mails, self.ham_mails =0,0\n",
    "        for i in self.labels:\n",
    "            if i:\n",
    "                self.spam_mails+=1\n",
    "            else:\n",
    "                self.ham_mails+=1\n",
    "        self.total_mails = self.spam_mails + self.ham_mails\n",
    "        self.spam_words = 0\n",
    "        self.ham_words = 0\n",
    "        self.tf_spam = dict()\n",
    "        self.tf_ham = dict()\n",
    "        self.idf_spam = dict()\n",
    "        self.idf_ham = dict()\n",
    "        for i in range(noOfMessages):\n",
    "            message_processed = process_message(self.mails[i])\n",
    "            count = list() #To keep track of whether the word has ocured in the message or not.\n",
    "                           #For IDF\n",
    "            for word in message_processed:\n",
    "                if self.labels[i]:\n",
    "                    self.tf_spam[word] = self.tf_spam.get(word, 0) + 1\n",
    "                    self.spam_words += 1\n",
    "                else:\n",
    "                    self.tf_ham[word] = self.tf_ham.get(word, 0) + 1\n",
    "                    self.ham_words += 1\n",
    "                if word not in count:\n",
    "                    count += [word]\n",
    "            for word in count:\n",
    "                if self.labels[i]:\n",
    "                    self.idf_spam[word] = self.idf_spam.get(word, 0) + 1\n",
    "                else:\n",
    "                    self.idf_ham[word] = self.idf_ham.get(word, 0) + 1\n",
    "    def calc_TF_IDF(self):\n",
    "        self.prob_spam = dict()\n",
    "        self.prob_ham = dict()\n",
    "        self.sum_tf_idf_spam = 0\n",
    "        self.sum_tf_idf_ham = 0\n",
    "        for word in self.tf_spam:\n",
    "            self.prob_spam[word] = (self.tf_spam[word]) * log((self.spam_mails + self.ham_mails) \\\n",
    "                                                          / (self.idf_spam[word] + self.idf_ham.get(word, 0)))\n",
    "            self.sum_tf_idf_spam += self.prob_spam[word]\n",
    "        for word in self.tf_spam:\n",
    "            self.prob_spam[word] = (self.prob_spam[word] + 1) / (self.sum_tf_idf_spam + len(list(self.prob_spam.keys())))\n",
    "            \n",
    "        for word in self.tf_ham:\n",
    "            self.prob_ham[word] = (self.tf_ham[word]) * log((self.spam_mails + self.ham_mails) \\\n",
    "                                                          / (self.idf_spam.get(word, 0) + self.idf_ham[word]))\n",
    "            self.sum_tf_idf_ham += self.prob_ham[word]\n",
    "        for word in self.tf_ham:\n",
    "            self.prob_ham[word] = (self.prob_ham[word] + 1) / (self.sum_tf_idf_ham + len(list(self.prob_ham.keys())))\n",
    "            \n",
    "    \n",
    "        self.prob_spam_mail, self.prob_ham_mail = self.spam_mails / self.total_mails, self.ham_mails / self.total_mails \n",
    "                    \n",
    "    def classify(self, processed_message):\n",
    "        pSpam, pHam = 0, 0\n",
    "        for word in processed_message:                \n",
    "            if word in self.prob_spam:\n",
    "                pSpam += log(self.prob_spam[word])\n",
    "            else:\n",
    "                    pSpam -= log(self.sum_tf_idf_spam + len(list(self.prob_spam.keys())))\n",
    "            if word in self.prob_ham:\n",
    "                pHam += log(self.prob_ham[word])\n",
    "            else:\n",
    "                    pHam -= log(self.sum_tf_idf_ham + len(list(self.prob_ham.keys()))) \n",
    "\n",
    "            pSpam += log(self.prob_spam_mail)\n",
    "            pHam += log(self.prob_ham_mail)\n",
    "        return pSpam >= pHam\n",
    "    \n",
    "    def predict(self, testData):\n",
    "        result = dict()\n",
    "        for (i, message) in enumerate(testData):\n",
    "            processed_message = process_message(message)\n",
    "            result[i] = int(self.classify(processed_message))\n",
    "        return result                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(labels, predictions):\n",
    "    true_pos, true_neg, false_pos, false_neg = 0, 0, 0, 0\n",
    "    for i in range(len(labels)):\n",
    "        true_pos += int(labels[i] == 1 and predictions[i] == 1)\n",
    "        true_neg += int(labels[i] == 0 and predictions[i] == 0)\n",
    "        false_pos += int(labels[i] == 0 and predictions[i] == 1)\n",
    "        false_neg += int(labels[i] == 1 and predictions[i] == 0)\n",
    "    precision = true_pos / (true_pos + false_pos)\n",
    "    recall = true_pos / (true_pos + false_neg)\n",
    "    Fscore = 2 * precision * recall / (precision + recall)\n",
    "    accuracy = (true_pos + true_neg) / (true_pos + true_neg + false_pos + false_neg)\n",
    "\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "    print(\"F-score: \", Fscore)\n",
    "    print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.7630057803468208\n",
      "Recall:  0.7333333333333333\n",
      "F-score:  0.7478753541076487\n",
      "Accuracy:  0.9361091170136396\n"
     ]
    }
   ],
   "source": [
    "sc_tf_idf = SpamClassifier(trainData)\n",
    "sc_tf_idf.train()\n",
    "preds_tf_idf = sc_tf_idf.predict(testData['message'])\n",
    "metrics(list(testData['label']), preds_tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm = process_message('I cant pick the phone right now. Pls send a message')\n",
    "sc_tf_idf.classify(pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm = process_message('Congratulations ur awarded $500 ')\n",
    "sc_tf_idf.classify(pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
